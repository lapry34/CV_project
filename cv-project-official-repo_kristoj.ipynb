{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm","authorship_tag":"ABX9TyPH70ehimUXH9IWugiD89G8"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2454327,"sourceType":"datasetVersion","datasetId":1485541},{"sourceId":3209332,"sourceType":"datasetVersion","datasetId":1946896}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Drive Setup","metadata":{}},{"cell_type":"code","source":"# Google Drive Setup\n########################\n\n\n# Set up directories\nimport os\nBASE_PATH = '/kaggle/working'\nMODEL_SAVE_DIR = os.path.join(BASE_PATH, 'trained_models')\nDATASET_DIR = '/kaggle/input'\nMVTEC_DATA_DIR = os.path.join(DATASET_DIR, 'mvtec-ad')\nBTAD_DATA_DIR = os.path.join(DATASET_DIR, 'btad-beantech-anomaly-detection')\n\n# Create directories if they don't exist\nos.makedirs(MODEL_SAVE_DIR, exist_ok=True)\nos.makedirs(MVTEC_DATA_DIR, exist_ok=True)\nos.makedirs(BTAD_DATA_DIR, exist_ok=True)\n\nUSE_DYT = True\nDYT_INIT_A = 0.5\n\n# Set num_workers for data loaders\nNUM_WORKERS_PARAM = {\n    'num_workers': 0  # Set to 0 for Colab to avoid crashes\n}\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# Imports\n########################\n\n# Standard libraries\nimport random\nimport argparse\nfrom collections import OrderedDict\nfrom itertools import chain\nimport time\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Image processing and visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport skimage.io as io\nfrom skimage.io import imread\nfrom skimage.measure import label, regionprops\nfrom skimage import measure\nfrom PIL import Image\nimport cv2\nfrom scipy.ndimage import gaussian_filter, median_filter\n\n# PyTorch and deep learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport torch.utils.data as data\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision.models as models\nimport torchvision.utils as utils\nfrom torchvision import transforms\nfrom einops import rearrange, repeat\nimport wandb\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Globals","metadata":{}},{"cell_type":"code","source":"# Globals\n########################\n\nclass Config():\n    def __init__(self):\n        self.USE_CUDA = True and torch.cuda.is_available()\n\n# Minimum number of patches for Vision Transformer\nMIN_NUM_PATCHES = 16\n\n# Visualization settings\nPLOT_COLORS = {\"normal\": \"green\", \"anomaly\": \"red\"}\nPLOT_STYLE = \"whitegrid\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"# Utils\n########################\n\ndef Normalise(score_map):\n    \"\"\"Normalize score map to range [0,1]\"\"\"\n    max_score = score_map.max()\n    min_score = score_map.min()\n    scores = (score_map - min_score) / (max_score - min_score)\n    return scores\n\ndef Mean_var(score_map):\n    \"\"\"Calculate mean and variance of a score map\"\"\"\n    mean = np.mean(score_map)\n    var = np.var(score_map)\n    return mean, var\n\ndef Filter(score_map, type=0):\n    \"\"\"\n    Apply filtering to score map\n    Parameters\n    ----------\n    score_map : score map as tensor or ndarray\n    type : Int, optional\n            DESCRIPTION. The values are:\n            0 = Gaussian\n            1 = Median\n\n    Returns\n    -------\n    score: Filtered score\n    \"\"\"\n    if type == 0:\n        score = gaussian_filter(score_map, sigma=4)\n    if type == 1:\n        score = median_filter(score_map, size=3)\n    return score\n\ndef Binarization(mask, thres=0., type=0):\n    \"\"\"Binarize a mask using threshold\"\"\"\n    if type == 0:\n        mask = np.where(mask > thres, 1., 0.)\n    elif type == 1:\n        mask = np.where(mask > thres, mask, 0.)\n    return mask\n\ndef plot(image, grnd_truth, score):\n    \"\"\"Plot image, ground truth and predicted score\"\"\"\n    plt.figure(figsize=(15, 5))\n    plt.subplot(131)\n    plt.imshow(image[0].permute(1, 2, 0))\n    plt.title('Original Image')\n    plt.subplot(132)\n    plt.imshow(grnd_truth.squeeze(0).squeeze(0))\n    plt.title('Ground Truth')\n    plt.subplot(133)\n    plt.imshow(score)\n    plt.title('Anomaly Score')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.pause(1)\n    plt.show()\n\ndef plot_enhanced(image, grnd_truth, score, threshold=None, save_path=None):\n    \"\"\"Enhanced plot with threshold and better visualization\"\"\"\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        plt.figure(figsize=(18, 5))\n\n        # Original image\n        plt.subplot(141)\n        plt.imshow(image[0].permute(1, 2, 0))\n        plt.title('Original Image')\n        plt.axis('off')\n\n        # Ground truth\n        plt.subplot(142)\n        plt.imshow(grnd_truth.squeeze(0).squeeze(0), cmap='gray')\n        plt.title('Ground Truth')\n        plt.axis('off')\n\n        # Anomaly score\n        plt.subplot(143)\n        heatmap = plt.imshow(score, cmap='jet')\n        plt.title('Anomaly Score')\n        plt.axis('off')\n        plt.colorbar(heatmap, fraction=0.046, pad=0.04)\n\n        # Thresholded result (if threshold provided)\n        if threshold is not None:\n            plt.subplot(144)\n            binary_mask = Binarization(score, threshold)\n            plt.imshow(binary_mask, cmap='gray')\n            plt.title(f'Binary Result (t={threshold:.3f})')\n            plt.axis('off')\n\n        plt.tight_layout()\n\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef plot_roc_curve(fpr, tpr, auc_score, save_path=None):\n    \"\"\"Plot ROC curve with AUC score\"\"\"\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        plt.figure(figsize=(8, 8))\n        plt.plot(fpr, tpr, lw=2, color='darkorange', label=f'ROC curve (AUC = {auc_score:.3f})')\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic')\n        plt.legend(loc=\"lower right\")\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef plot_precision_recall_curve(precision, recall, pr_auc, save_path=None):\n    \"\"\"Plot precision-recall curve with AUC score\"\"\"\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        plt.figure(figsize=(8, 8))\n        plt.plot(recall, precision, lw=2, color='green', label=f'PR curve (AUC = {pr_auc:.3f})')\n        plt.fill_between(recall, precision, alpha=0.2, color='green')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title('Precision-Recall Curve')\n        plt.legend(loc=\"lower left\")\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, save_path=None):\n    \"\"\"Plot confusion matrix using seaborn\"\"\"\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        cm = confusion_matrix(y_true, y_pred)\n        plt.figure(figsize=(8, 8))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                    xticklabels=['Normal', 'Anomaly'],\n                    yticklabels=['Normal', 'Anomaly'])\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.title('Confusion Matrix')\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef plot_score_distributions(normal_scores, anomaly_scores, threshold=None, save_path=None):\n    \"\"\"Plot histogram of normal and anomaly scores with threshold line if provided\"\"\"\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        plt.figure(figsize=(10, 6))\n        sns.histplot(normal_scores, color=PLOT_COLORS[\"normal\"], label=\"Normal\", alpha=0.6, kde=True)\n        sns.histplot(anomaly_scores, color=PLOT_COLORS[\"anomaly\"], label=\"Anomaly\", alpha=0.6, kde=True)\n\n        if threshold is not None:\n            plt.axvline(x=threshold, color='black', linestyle='--', label=f'Threshold: {threshold:.3f}')\n\n        plt.xlabel('Anomaly Score')\n        plt.ylabel('Density')\n        plt.title('Distribution of Anomaly Scores')\n        plt.legend()\n\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef visualize_regions(image, score_map, threshold, min_area=100, save_path=None):\n    \"\"\"Visualize detected anomaly regions\"\"\"\n    # Threshold the score map and find contours\n    binary_mask = Binarization(score_map, threshold)\n    labeled_mask = measure.label(binary_mask)\n    regions = measure.regionprops(labeled_mask)\n\n    # Filter small regions\n    filtered_regions = [region for region in regions if region.area >= min_area]\n\n    # Visualize\n    with sns.plotting_context(\"talk\"):\n        sns.set_style(PLOT_STYLE)\n        plt.figure(figsize=(12, 8))\n\n        # Original image\n        plt.subplot(121)\n        plt.imshow(image[0].permute(1, 2, 0))\n        plt.title('Original Image')\n        plt.axis('off')\n\n        # Image with detected regions\n        plt.subplot(122)\n        plt.imshow(image[0].permute(1, 2, 0))\n\n        # Draw bounding boxes around regions\n        for region in filtered_regions:\n            minr, minc, maxr, maxc = region.bbox\n            rect = plt.Rectangle((minc, minr), maxc - minc, maxr - minr,\n                                fill=False, edgecolor='red', linewidth=2)\n            plt.gca().add_patch(rect)\n\n            # Add area text\n            plt.text(minc, minr - 5, f\"Area: {region.area}\",\n                    color='white', fontsize=9, backgroundcolor='red')\n\n        plt.title(f'Detected Anomalies (n={len(filtered_regions)})')\n        plt.axis('off')\n\n        plt.tight_layout()\n        if save_path:\n            plt.savefig(save_path, bbox_inches='tight')\n        plt.show()\n\ndef binImage(heatmap, thres=0):\n    \"\"\"Binarize heatmap using threshold\"\"\"\n    _, heatmap_bin = cv2.threshold(heatmap, thres, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    return heatmap_bin\n\ndef selectMaxConnect(heatmap):\n    \"\"\"Select largest connected component\"\"\"\n    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)\n    max_label = 0\n    max_num = 0\n    for i in range(1, num+1):\n        if np.sum(labeled_img == i) > max_num:\n            max_num = np.sum(labeled_img == i)\n            max_label = i\n    lcc = (labeled_img == max_label)\n    if max_num == 0:\n        lcc = (labeled_img == -1)\n    lcc = lcc + 0\n    return lcc\n\n# Initialize weight function\ndef initialize_weights(*models):\n    \"\"\"Initialize network weights using kaiming normal\"\"\"\n    for model in models:\n        for module in model.modules():\n            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n                nn.init.kaiming_normal_(module.weight)\n                if module.bias is not None:\n                    module.bias.data.zero_()\n            elif isinstance(module, nn.BatchNorm2d):\n                module.weight.data.fill_(1)\n                module.bias.data.zero_()\n\ndef add_noise(latent, noise_type=\"gaussian\", sd=0.2):\n    \"\"\"\n    Add noise to latent features\n\n    Arguments:\n    'gaussian' (string): Gaussian-distributed additive noise.\n    'speckle' (string) : Multiplicative noise using out = image + n*image, where n is uniform noise.\n    'sd' (float) : standard deviation used for generating noise\n    \"\"\"\n    assert sd >= 0.0\n    if noise_type == \"gaussian\":\n        mean = 0.\n        n = torch.distributions.Normal(torch.tensor([mean]), torch.tensor([sd]))\n        noise = n.sample(latent.size()).squeeze(-1).cuda()\n        latent = latent + noise\n        return latent\n\n    if noise_type == \"speckle\":\n        noise = torch.randn(latent.size()).cuda()\n        latent = latent + latent * noise\n        return latent\n\ndef ran_generator(length, shots=1):\n    \"\"\"Generate random indices\"\"\"\n    rand_list = random.sample(range(0, length), shots)\n    return rand_list\n\nclass SSIM(torch.nn.Module):\n    def __init__(self, window_size=11, size_average=True):\n        super(SSIM, self).__init__()\n        self.window_size = window_size\n        self.size_average = size_average\n        self.channel = 1\n        self.window = self.create_window(window_size, self.channel)\n\n    def gaussian(self, window_size, sigma):\n        gauss = torch.Tensor([np.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n        return gauss/gauss.sum()\n\n    def create_window(self, window_size, channel):\n        _1D_window = self.gaussian(window_size, 1.5).unsqueeze(1)\n        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n        return window\n\n    def _ssim(self, img1, img2, window, window_size, channel, size_average=True):\n        mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)\n        mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n\n        mu1_sq = mu1.pow(2)\n        mu2_sq = mu2.pow(2)\n        mu1_mu2 = mu1*mu2\n\n        sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq\n        sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq\n        sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2\n\n        C1 = 0.01**2\n        C2 = 0.03**2\n\n        ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n\n        if size_average:\n            return ssim_map.mean()\n        else:\n            return ssim_map.mean(1).mean(1).mean(1)\n\n    def forward(self, img1, img2):\n        (_, channel, _, _) = img1.size()\n\n        if channel == self.channel and self.window.data.type() == img1.data.type():\n            window = self.window\n        else:\n            window = self.create_window(self.window_size, channel)\n\n            if img1.is_cuda:\n                window = window.cuda(img1.get_device())\n            window = window.type_as(img1)\n\n            self.window = window\n            self.channel = channel\n\n        return self._ssim(img1, img2, window, self.window_size, channel, self.size_average)\n\ndef log_gaussian(x, mean, logvar):\n    '''\n    Computes the Gaussian log-likelihoods\n    '''\n    x = x.unsqueeze(-1).expand_as(logvar)\n    a = (x - mean) ** 2  # works on multiple samples thanks to tensor broadcasting\n    log_p = (logvar + a / (torch.exp(logvar))).sum(2)\n    log_p = -0.5 * (np.log(2 * np.pi) + log_p)\n\n    return log_p\n\ndef log_gmm(x, means, logvars, weights, total=True):\n    '''\n    Computes the Gaussian Mixture Model log-likelihoods\n    '''\n    res = -log_gaussian(x, means, logvars)  # negative of log likelihood\n\n    res = weights * res\n\n    if total:\n        return torch.sum(res, 2)\n    else:\n        return res\n\ndef mdn_loss_function(x, means, logvars, weights, test=False):\n    if test:\n        res = log_gmm(x, means, logvars, weights)\n    else:\n        res = torch.mean(torch.sum(log_gmm(x, means, logvars, weights), 1))\n    return res\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# Data\n########################\n\ndef read_files(root, d, product, data_motive='train', use_good=True, normal=True):\n    '''\n    Return the path of the train directory and list of train images\n\n    Parameters:\n        root : root directory of mvtech images\n        d = List of directories in the root directory\n        product : name of the product to return the images for single class training\n        data_motive : Can be 'train' or 'test' or 'ground_truth'\n        use_good : To use the data in the good folder\n        normal : Signify if the normal images are included\n\n    Returns:\n        Path and Image ordered dict for the dataset\n    '''\n    files = next(os.walk(os.path.join(root, d)))[1]\n    for d_in in files:\n        if os.path.isdir(os.path.join(root, d, d_in)):\n            if d_in == data_motive:\n                im_pt = OrderedDict()\n                file = os.listdir(os.path.join(root, d, d_in))\n\n                for i in file:\n                    if os.path.isdir(os.path.join(root, d, d_in, i)):\n                        if (data_motive == 'train'):\n                            tr_img_pth = os.path.join(root, d, d_in, i)\n                            images = os.listdir(tr_img_pth)\n                            im_pt[tr_img_pth] = images\n                            print(f'total {d_in} images of {i} {d} are: {len(images)}')\n\n                        if (data_motive == 'test'):\n                            if (use_good == False) and (i == 'good') and normal != True:\n                                print(f'the good images for {d_in} images of {i} {d} is not included in the test anomalous data')\n                            elif (use_good == False) and (i != 'good') and normal != True:\n                                tr_img_pth = os.path.join(root, d, d_in, i)\n                                images = os.listdir(tr_img_pth)\n                                im_pt[tr_img_pth] = images\n                                print(f'total {d_in} images of {i} {d} are: {len(images)}')\n                            elif (use_good == True) and (i == 'good') and (normal == True):\n                                tr_img_pth = os.path.join(root, d, d_in, i)\n                                images = os.listdir(tr_img_pth)\n                                im_pt[tr_img_pth] = images\n                                print(f'total {d_in} images of {i} {d} are: {len(images)}')\n                        if (data_motive == 'ground_truth'):\n                            tr_img_pth = os.path.join(root, d, d_in, i)\n                            images = os.listdir(tr_img_pth)\n                            im_pt[tr_img_pth] = images\n                            print(f'total {d_in} images of {i} {d} are: {len(images)}')\n                if product == \"all\":\n                    return\n                else:\n                    return im_pt\n\ndef load_images(path, image_name):\n    \"\"\"Load image from path\"\"\"\n    return imread(os.path.join(path, image_name))\n\ndef Train_data(root, product='bottle', use_good=True):\n    '''\n    Return the path of the train directory and list of train images\n    '''\n    dir = os.listdir(root)\n\n    for d in dir:\n        if product == \"all\":\n            read_files(root, d, product, data_motive='train')\n        elif product == d:\n            pth_img = read_files(root, d, product, data_motive='train')\n            return pth_img\n\ndef Test_anom_data(root, product='bottle', use_good=False):\n    '''\n    Return path and images for anomalous test data\n    '''\n    dir = os.listdir(root)\n\n    for d in dir:\n        if product == \"all\":\n            read_files(root, d, product, data_motive='test', use_good=use_good, normal=False)\n        elif product == d:\n            pth_img_dict = read_files(root, d, product, data_motive='test', use_good=use_good, normal=False)\n            return pth_img_dict\n\ndef Test_anom_mask(root, product='bottle', use_good=False):\n    '''\n    Return path and images for anomalous test masks\n    '''\n    dir = os.listdir(root)\n\n    for d in dir:\n        if product == \"all\":\n            read_files(root, d, product, data_motive='test', use_good=use_good, normal=False)\n        elif product == d:\n            pth_img_dict = read_files(root, d, product, data_motive='ground_truth', use_good=use_good, normal=False)\n            return pth_img_dict\n\ndef Test_normal_data(root, product='bottle', use_good=True):\n    '''\n    Return path and images for normal test data\n    '''\n    if product == 'all':\n        print('Please choose a valid product. Normal test data can be seen product wise')\n        return\n    dir = os.listdir(root)\n\n    for d in dir:\n        if product == d:\n            pth_img = read_files(root, d, product, data_motive='test', use_good=True, normal=True)\n            return pth_img\n\ndef Process_mask(mask):\n    \"\"\"Process mask to binary format\"\"\"\n    mask = np.where(mask > 0., 1, mask)\n    return torch.tensor(mask)\n\nclass Mvtec:\n    def __init__(self, batch_size, root=MVTEC_DATA_DIR, product='bottle'):\n        self.root = root\n        self.batch = batch_size\n        self.product = product\n        torch.manual_seed(123)\n\n        if self.product == 'all':\n            print('--------Please select a valid product.......See Train_data function-----------')\n        else:\n            # Importing all the image_path dictionaries for test and train data\n            train_path_images = Train_data(root=self.root, product=self.product)\n            test_anom_path_images = Test_anom_data(root=self.root, product=self.product)\n            test_anom_mask_path_images = Test_anom_mask(root=self.root, product=self.product)\n            test_norm_path_images = Test_normal_data(root=self.root, product=self.product)\n\n            # Image Transformation\n            T = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((550, 550)),\n                transforms.CenterCrop(512),\n                transforms.ToTensor(),\n            ])\n\n            train_normal_image = torch.stack([T(load_images(j, i)) for j in train_path_images.keys() for i in train_path_images[j]])\n            test_anom_image = torch.stack([T(load_images(j, i)) for j in test_anom_path_images.keys() for i in test_anom_path_images[j]])\n            test_normal_image = torch.stack([T(load_images(j, i)) for j in test_norm_path_images.keys() for i in test_norm_path_images[j]])\n\n            train_normal_mask = torch.zeros(train_normal_image.size(0), 1, train_normal_image.size(2), train_normal_image.size(3))\n            test_normal_mask = torch.zeros(test_normal_image.size(0), 1, test_normal_image.size(2), test_normal_image.size(3))\n            test_anom_mask = torch.stack([Process_mask(T(load_images(j, i))) for j in test_anom_mask_path_images.keys() for i in test_anom_mask_path_images[j]])\n\n            train_normal = tuple(zip(train_normal_image, train_normal_mask))\n            test_anom = tuple(zip(test_anom_image, test_anom_mask))\n            test_normal = tuple(zip(test_normal_image, test_normal_mask))\n\n            print(f' --Size of {self.product} train loader: {train_normal_image.size()}--')\n            if test_anom_image.size(0) == test_anom_mask.size(0):\n                print(f' --Size of {self.product} test anomaly loader: {test_anom_image.size()}--')\n            else:\n                print(f'[!Info] Size Mismatch between Anomaly images {test_anom_image.size()} and Masks {test_anom_mask.size()} Loaded')\n            print(f' --Size of {self.product} test normal loader: {test_normal_image.size()}--')\n\n            # Create validation set\n            num = ran_generator(len(test_anom), 10)\n            val_anom = [test_anom[i] for i in num]\n            num = ran_generator(len(test_normal), 10)\n            val_norm = [test_normal[j] for j in num]\n            val_set = [*val_norm, *val_anom]\n            print(f' --Total Image in {self.product} Validation loader: {len(val_set)}--')\n\n            # Final Data Loader - Updated with num_workers=0\n            self.train_loader = torch.utils.data.DataLoader(train_normal, batch_size=batch_size, shuffle=True, **NUM_WORKERS_PARAM)\n            self.test_anom_loader = torch.utils.data.DataLoader(test_anom, batch_size=batch_size, shuffle=False, **NUM_WORKERS_PARAM)\n            self.test_norm_loader = torch.utils.data.DataLoader(test_normal, batch_size=batch_size, shuffle=False, **NUM_WORKERS_PARAM)\n            self.validation_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, **NUM_WORKERS_PARAM)\n\nclass BTADDataset(data.Dataset):\n    def __init__(self, images, masks=None, resize=True):\n        \"\"\"\n        BTAD dataset class\n\n        Args:\n            images: List of image tensors or paths\n            masks: List of mask tensors or paths (optional)\n            resize: Whether to resize images\n        \"\"\"\n        self.images = images\n        self.masks = masks\n        self.resize = resize\n\n        self.resize_transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((300, 300)),  # Adjusted size\n            transforms.ToTensor()])\n        self.default_transform = transforms.Compose([transforms.ToTensor()])\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, i):\n        # Check if image is already a tensor or a path\n        if isinstance(self.images[i], str):\n            # Load image from path\n            image_ = io.imread(self.images[i])\n\n            # Convert grayscale to RGB if needed\n            if len(image_.shape) < 3:\n                image_ = np.stack((image_,) * 3, axis=-1)\n\n            if self.resize:\n                image = self.resize_transform(image_)\n            else:\n                image = self.default_transform(image_)\n        else:\n            # Image is already a tensor\n            image = self.images[i]\n\n        # Check if masks are provided\n        if self.masks is not None:\n            if isinstance(self.masks[i], str):\n                # Load mask from path\n                mask_ = io.imread(self.masks[i], as_gray=True)\n                mask = torch.from_numpy(mask_).unsqueeze(0).float()\n            else:\n                # Mask is already a tensor\n                mask = self.masks[i]\n        else:\n            # Create empty label (for training on normal data)\n            mask = torch.zeros(1, image.size(1), image.size(2))\n\n        return image, mask\n\ndef load_btad_dataset(root_dir, product, batch_size, mode='train', resize=True, use_normal=True, anomalous=False):\n    \"\"\"\n    Load BTAD dataset directly from Google Drive structure\n\n    Args:\n        root_dir: Root directory of BTAD dataset\n        product: Product category (e.g., '01', '02', '03')\n        batch_size: Batch size for data loader\n        mode: 'train' or 'test'\n        resize: Whether to resize images\n        use_normal: Include normal ('ok') samples\n        anomalous: Specify if loading anomalous ('ko') data\n\n    Returns:\n        DataLoader for the specified dataset\n    \"\"\"\n    # Check if product is valid\n    if not os.path.exists(os.path.join(root_dir, product)):\n        available_products = os.listdir(root_dir)\n        raise ValueError(f\"Product '{product}' not found. Available products: {available_products}\")\n\n    # Path to the product folder\n    product_path = os.path.join(root_dir, product)\n\n    # Get image paths based on mode\n    image_paths = []\n    mask_paths = []\n\n    if mode == 'train':\n        # For training, we usually just use the normal samples\n        train_path = os.path.join(product_path, 'train')\n        if os.path.exists(train_path):\n            # In BTAD, normal samples are labeled as 'ok'\n            ok_path = os.path.join(train_path, 'ok')\n            if os.path.exists(ok_path) and use_normal:\n                for img_file in os.listdir(ok_path):\n                    if img_file.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n                        image_paths.append(os.path.join(ok_path, img_file))\n\n            # In BTAD, anomalous samples are labeled as 'ko'\n            ko_path = os.path.join(train_path, 'ko')\n            if os.path.exists(ko_path) and anomalous:\n                for img_file in os.listdir(ko_path):\n                    if img_file.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n                        image_paths.append(os.path.join(ko_path, img_file))\n        else:\n            print(f\"Warning: Train path {train_path} does not exist.\")\n\n    elif mode == 'test':\n        # For testing, include both normal and anomalous samples\n        test_path = os.path.join(product_path, 'test')\n        gt_path = os.path.join(product_path, 'ground_truth')\n\n        if os.path.exists(test_path):\n            # Process normal samples (ok)\n            ok_path = os.path.join(test_path, 'ok')\n            if os.path.exists(ok_path) and use_normal:\n                for img_file in os.listdir(ok_path):\n                    if img_file.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n                        image_paths.append(os.path.join(ok_path, img_file))\n                        # Add empty mask path for normal samples\n                        mask_paths.append(None)\n\n            # Process anomalous samples (ko)\n            ko_path = os.path.join(test_path, 'ko')\n            if os.path.exists(ko_path) and anomalous:\n                for img_file in os.listdir(ko_path):\n                    if img_file.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n                        image_paths.append(os.path.join(ko_path, img_file))\n\n                        # Try to find corresponding mask in ground_truth\n                        gt_ko_path = os.path.join(gt_path, 'ko') if os.path.exists(gt_path) else None\n                        if gt_ko_path and os.path.exists(gt_ko_path):\n                            # Find matching mask (might have different extension)\n                            img_base = os.path.splitext(img_file)[0]\n                            mask_found = False\n                            for ext in ['.png', '.jpg', '.jpeg', '.bmp']:\n                                mask_file = img_base + ext\n                                mask_path = os.path.join(gt_ko_path, mask_file)\n                                if os.path.exists(mask_path):\n                                    mask_paths.append(mask_path)\n                                    mask_found = True\n                                    break\n\n                            if not mask_found:\n                                print(f\"Warning: No mask found for {img_file}\")\n                                mask_paths.append(None)\n                        else:\n                            # No ground truth directory\n                            mask_paths.append(None)\n        else:\n            print(f\"Warning: Test path {test_path} does not exist.\")\n\n    print(f\"Found {len(image_paths)} images for {product} ({mode}, {'ok' if use_normal else ''}{'+ko' if anomalous else ''})\")\n\n    # If no masks were found or provided, set to None\n    if len(mask_paths) == 0 or all(m is None for m in mask_paths):\n        mask_paths = None\n\n    # Create dataset\n    dataset = BTADDataset(image_paths, mask_paths, resize)\n    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=(mode == 'train'), **NUM_WORKERS_PARAM)\n\n    return data_loader\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"# Network\n########################\n\nclass DyT(nn.Module):\n    \"\"\" Dynamic Tanh Layer \"\"\"\n    def __init__(self, dim, init_a=DYT_INIT_A):\n        super().__init__()\n        self.alpha = nn.Parameter(torch.tensor(init_a, dtype=torch.float32)) #0.5 come il paper di Lecun\n        self.gamma = nn.Parameter(torch.ones(dim, dtype=torch.float32) * 0.9) #Come il paper di LeCun, ma gamma leggermente più piccolo\n        self.beta = nn.Parameter(torch.zeros(dim, dtype=torch.float32)) #Come il paper di LeCun\n        # To ensure gamma and beta can be broadcasted correctly with (B, N, D) input\n        # they need to be shaped as (1, 1, D) or (D)\n        # PyTorch handles (D) broadcasting to (B,N,D) if op is like self.gamma * tensor\n\n    def forward(self, x):\n        # x shape: (batch_size, num_patches, embed_dim)\n        return self.gamma * torch.tanh(self.alpha * x) + self.beta\n\nclass Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(x, **kwargs) + x\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        if USE_DYT:\n            self.norm = DyT(dim)\n        else:\n            self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Linear(hidden_dim, dim)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads=8):\n        super().__init__()\n        self.heads = heads\n        self.scale = dim ** -0.5\n\n        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.to_out = nn.Linear(dim, dim)\n\n    def forward(self, x, mask=None):\n        b, n, _, h = *x.shape, self.heads\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n\n        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n        mask_value = -torch.finfo(dots.dtype).max\n\n        if mask is not None:\n            mask = F.pad(mask.flatten(1), (1, 0), value=True)\n            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n            mask = mask[:, None, :] * mask[:, :, None]\n            dots.masked_fill_(~mask, mask_value)\n            del mask\n\n        attn = dots.softmax(dim=-1)\n        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        out = self.to_out(out)\n        return out\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, mlp_dim):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                Residual(PreNorm(dim, Attention(dim, heads=heads))),\n                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n            ]))\n\n    def forward(self, x, mask=None):\n        for attn, ff in self.layers:\n            x = attn(x, mask=mask)\n            x = ff(x)\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=3):\n        super().__init__()\n        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n        num_patches = (image_size // patch_size) ** 2\n        patch_dim = channels * patch_size ** 2\n        assert num_patches > MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n\n        self.patch_size = patch_size\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n\n        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n\n        self.to_cls_token = nn.Identity()\n\n    def forward(self, img, mask=None):\n        p = self.patch_size\n\n        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=p, p2=p)\n        x = self.patch_to_embedding(x)\n        b, n, _ = x.shape\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n\n        x = self.transformer(x, mask)\n\n        x = self.to_cls_token(x[:, 1:, :])\n\n        return x\n\nclass Unity(nn.Module):\n    def __init__(self, ks, in_ch=512):\n        super(Unity, self).__init__()\n        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=512, kernel_size=ks)\n\n    def forward(self, x):\n        return F.relu(self.conv(x), inplace=True)\n\nclass Spatial_Scorer(nn.Module):\n    def __init__(self, in_dim=512, test=False):\n        super(Spatial_Scorer, self).__init__()\n        self.test = test\n\n        self.layers = nn.Sequential(\n            nn.Linear(in_dim, 256),\n            nn.ReLU(True),\n            nn.Linear(256, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 1),\n            nn.Tanh())\n\n        if not self.test:\n            print(\"Initializing Spatial scorer network...\")\n            initialize_weights(self.layers)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        F_out = self.layers(x)\n        return F_out\n\nclass DigitCaps(nn.Module):\n    def __init__(self, out_num_caps=1, in_num_caps=8*8*64, in_dim_caps=8, out_dim_caps=512, decode_idx=-1):\n        super(DigitCaps, self).__init__()\n\n        self.conf = Config()\n        self.in_dim_caps = in_dim_caps\n        self.in_num_caps = in_num_caps\n        self.out_dim_caps = out_dim_caps\n        self.out_num_caps = out_num_caps\n        self.decode_idx = decode_idx\n        self.W = nn.Parameter(0.01 * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))\n\n    def forward(self, x):\n        # x size: batch x 1152 x 8\n        x_hat = torch.squeeze(torch.matmul(self.W, x[:, None, :, :, None]), dim=-1)\n        x_hat_detached = x_hat.detach()\n        # x_hat size: batch x ndigits x 1152 x 16\n        b = Variable(torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps))\n        # b size: batch x ndigits x 1152\n        if self.conf.USE_CUDA:\n            b = b.cuda()\n\n        # Routing algorithm\n        num_iters = 3\n        for i in range(num_iters):\n            c = F.softmax(b, dim=1)\n            # c size: batch x ndigits x 1152\n            if i == num_iters - 1:\n                # output size: batch x ndigits x 1 x 16\n                outputs = self.squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))\n            else:\n                outputs = self.squash(torch.sum(c[:, :, :, None] * x_hat_detached, dim=-2, keepdim=True))\n                b = b + torch.sum(outputs * x_hat_detached, dim=-1)\n\n        outputs = torch.squeeze(outputs, dim=-2)  # squeezing to remove ones at the dimension -1\n\n        # Choose the longest vector as the one to decode\n        if self.decode_idx == -1:\n            classes = torch.sqrt((outputs ** 2).sum(2))\n            classes = F.softmax(classes, dim=1)\n            _, max_length_indices = classes.max(dim=1)\n        else:  # always choose the same digitcaps\n            max_length_indices = torch.ones(outputs.size(0)).long() * self.decode_idx\n            if self.conf.USE_CUDA:\n                max_length_indices = max_length_indices.cuda()\n\n        masked = Variable(torch.sparse.torch.eye(self.out_num_caps))\n        if self.conf.USE_CUDA:\n            masked = masked.cuda()\n        masked = masked.index_select(dim=0, index=max_length_indices)\n        t = (outputs * masked[:, :, None]).sum(dim=1).unsqueeze(1)\n\n        return t, outputs\n\n    def squash(self, input_tensor):\n        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n        return output_tensor\nclass decoder2(nn.Module):\n    def __init__(self, in_channels):\n        super(decoder2, self).__init__()\n        self.decoder2 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=in_channels, out_channels=16, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(16, affine=True),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 32, 9, stride=3, padding=1),\n            nn.BatchNorm2d(32, affine=True),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(32, 32, 7, stride=5, padding=1),\n            nn.BatchNorm2d(32, affine=True),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(32, 16, 9, stride=2),\n            nn.BatchNorm2d(16, affine=True),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 8, 6, stride=1),\n            nn.BatchNorm2d(8, affine=True),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(8, 3, 11, stride=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        recon = self.decoder2(x)\n        return recon\n\nclass VT_AE(nn.Module):\n    def __init__(self, image_size=512,\n                patch_size=64,\n                num_classes=1,\n                dim=512,\n                depth=6,\n                heads=8,\n                mlp_dim=1024,\n                train=True):\n\n        super(VT_AE, self).__init__()\n        self.vt = ViT(\n            image_size=image_size,\n            patch_size=patch_size,\n            num_classes=num_classes,\n            dim=dim,\n            depth=depth,\n            heads=heads,\n            mlp_dim=mlp_dim)\n\n        self.decoder = decoder2(8)\n        self.Digcap = DigitCaps(in_num_caps=((image_size//patch_size)**2)*8*8, in_dim_caps=8)\n        self.mask = torch.ones(1, image_size//patch_size, image_size//patch_size).bool().cuda()\n        self.Train = train\n\n        if self.Train:\n            print(\"\\nInitializing network weights...\")\n            initialize_weights(self.vt, self.decoder)\n\n    def forward(self, x):\n        b = x.size(0)\n        encoded = self.vt(x, self.mask)\n        if self.Train:\n            encoded = add_noise(encoded)\n        encoded1, vectors = self.Digcap(encoded.view(b, encoded.size(1)*8*8, -1))\n        recons = self.decoder(encoded1.view(b, -1, 8, 8))\n\n        return encoded, recons\n\nclass MDN(nn.Module):\n    def __init__(self, input_dim=512, out_dim=512, layer_size=512, coefs=10, test=False, sd=0.5):\n        super(MDN, self).__init__()\n        self.in_features = input_dim\n\n        self.pi = nn.Linear(layer_size, coefs, bias=False)\n        self.mu = nn.Linear(layer_size, out_dim * coefs, bias=False)  # mean\n        self.sigma_sq = nn.Linear(layer_size, out_dim * coefs, bias=False)  # isotropic independent variance\n        self.out_dim = out_dim\n        self.coefs = coefs\n        self.test = test\n        self.sd = sd\n\n    def forward(self, x):\n        ep = np.finfo(float).eps\n        x = torch.clamp(x, ep)\n\n        pi = F.softmax(self.pi(x), dim=-1)\n        sigma_sq = F.softplus(self.sigma_sq(x)).view(x.size(0), x.size(1), self.in_features, -1)  # logvar\n        mu = self.mu(x).view(x.size(0), x.size(1), self.in_features, -1)  # mean\n        return pi, mu, sigma_sq\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Train\n########################\n\ndef train_model(args):\n    \"\"\"\n    Train the anomaly detection model\n\n    Args:\n        args: Command line arguments\n    \"\"\"\n    print(f\"\\n{'='*20} Training on {args.dataset} dataset {'='*20}\")\n    print(f\"Product: {args.product}, Epochs: {args.epochs}, Learning Rate: {args.learning_rate}\")\n\n    # Initialize wandb\n    wandb.login(key='bee3a112e4b13d4b3341435b7e978e7c4b8c7e31')\n    wandb.init(\n        project=f\"anomaly-detection-{args.dataset}\",\n        config={\n            \"dataset\": args.dataset,\n            \"product\": args.product,\n            \"epochs\": args.epochs,\n            \"batch_size\": args.batch_size,\n            \"learning_rate\": args.learning_rate,\n            \"patch_size\": args.patch_size\n        }\n    )\n\n    # Initialize tensorboard\n    writer = SummaryWriter()\n\n    # Initialize SSIM loss\n    ssim_loss = SSIM().cuda()\n\n    # Load dataset\n    if args.dataset.lower() == 'mvtec':\n        data = Mvtec(args.batch_size, root=MVTEC_DATA_DIR, product=args.product)\n    elif args.dataset.lower() == 'btad':\n        data = load_btad_dataset(os.path.join(BTAD_DATA_DIR, 'train.csv'), args.batch_size)\n    else:\n        raise ValueError(f\"Dataset {args.dataset} not supported\")\n\n    # Initialize models\n    model = VT_AE(patch_size=args.patch_size, train=True).cuda()\n    G_estimate = MDN().cuda()\n\n    # Initialize optimizer\n    optimizer = Adam(list(model.parameters()) + list(G_estimate.parameters()),\n                    lr=args.learning_rate, weight_decay=0.0001)\n\n    # Set models to train mode\n    model.train()\n    G_estimate.train()\n\n    # Training loop\n    minloss = float('inf')\n    best_epoch = 0\n\n    print('\\nNetwork training started...')\n    for epoch in range(args.epochs):\n        epoch_losses = []\n        epoch_reconstruction_losses = []\n        epoch_ssim_losses = []\n        epoch_mdn_losses = []\n\n        # Get the right dataloader based on dataset\n        if args.dataset.lower() == 'mvtec':\n            train_loader = data.train_loader\n        else:\n            train_loader = data\n\n        for images, masks in train_loader:\n            # Handle single channel images\n            if images.size(1) == 1:\n                images = torch.stack([images, images, images]).squeeze(2).permute(1, 0, 2, 3)\n\n            # Zero gradients\n            optimizer.zero_grad()\n\n            # Forward pass through models\n            vector, reconstructions = model(images.cuda())\n            pi, mu, sigma = G_estimate(vector)\n\n            # Calculate losses\n            reconstruction_loss = F.mse_loss(reconstructions, images.cuda(), reduction='mean')  # Reconstruction Loss\n            ssim_loss_val = -ssim_loss(images.cuda(), reconstructions)  # Structural similarity loss\n            mdn_loss = mdn_loss_function(vector, mu, sigma, pi)  # Mixture density network loss\n\n            # Total loss\n            total_loss = 5 * reconstruction_loss + 0.5 * ssim_loss_val + mdn_loss\n\n            # Store loss\n            epoch_losses.append(total_loss.item())\n            epoch_reconstruction_losses.append(reconstruction_loss.item())\n            epoch_ssim_losses.append(ssim_loss_val.item())\n            epoch_mdn_losses.append(mdn_loss.item())\n\n            # Log to tensorboard\n            writer.add_scalar('reconstruction_loss', reconstruction_loss.item(), epoch)\n            writer.add_scalar('ssim_loss', ssim_loss_val.item(), epoch)\n            writer.add_scalar('mdn_loss', mdn_loss.item(), epoch)\n            writer.add_histogram('feature_vectors', vector)\n\n            # Backpropagate and update weights\n            total_loss.backward()\n            optimizer.step()\n\n        # Calculate epoch average loss\n        avg_epoch_loss = np.mean(epoch_losses)\n        avg_reconstruction_loss = np.mean(epoch_reconstruction_losses)\n        avg_ssim_loss = np.mean(epoch_ssim_losses)\n        avg_mdn_loss = np.mean(epoch_mdn_losses)\n\n        # Log to wandb\n        wandb.log({\n            \"epoch\": epoch,\n            \"total_loss\": avg_epoch_loss,\n            \"reconstruction_loss\": avg_reconstruction_loss,\n            \"ssim_loss\": avg_ssim_loss,\n            \"mdn_loss\": avg_mdn_loss\n        })\n\n        # Log reconstructed images\n        if epoch % 10 == 0:\n            # Get a sample batch for visualization\n            sample_images, _ = next(iter(train_loader))\n            if sample_images.size(1) == 1:\n                sample_images = torch.stack([sample_images, sample_images, sample_images]).squeeze(2).permute(1, 0, 2, 3)\n\n            with torch.no_grad():\n                _, sample_reconstructions = model(sample_images.cuda())\n\n            # Create comparison grid\n            comparison = torch.cat([sample_images[:4], sample_reconstructions[:4].cpu()])\n            grid = utils.make_grid(comparison, nrow=4)\n\n            # Log to tensorboard and wandb\n            writer.add_image('Reconstructions', grid, epoch)\n            wandb.log({\"reconstructions\": wandb.Image(grid)})\n\n        # Log to tensorboard\n        writer.add_scalar('Average_Epoch_Loss', avg_epoch_loss, epoch)\n\n        print(f'Epoch {epoch+1}/{args.epochs}, Loss: {avg_epoch_loss:.6f}')\n\n        # Save best model\n        if avg_epoch_loss < minloss:\n            minloss = avg_epoch_loss\n            best_epoch = epoch\n            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n            model_path = os.path.join(MODEL_SAVE_DIR, f'VT_AE_{args.dataset}_{args.product}.pt')\n            g_path = os.path.join(MODEL_SAVE_DIR, f'G_estimate_{args.dataset}_{args.product}.pt')\n            torch.save(model.state_dict(), model_path)\n            torch.save(G_estimate.state_dict(), g_path)\n            print(f\"Saved best model at epoch {epoch+1} with loss {minloss:.6f}\")\n\n            # Save to wandb\n            wandb.save(model_path)\n            wandb.save(g_path)\n\n        # Print best epoch info\n        print(f'Best epoch so far: {best_epoch+1} with loss: {minloss:.6f}')\n\n    # Finish logging\n    writer.close()\n    wandb.finish()\n\n    print(f\"\\nTraining completed! Best model saved at epoch {best_epoch+1} with loss {minloss:.6f}\")\n    print(f\"Model saved at: {os.path.join(MODEL_SAVE_DIR, f'VT_AE_{args.dataset}_{args.product}.pt')}\")\n    print(f\"MDN model saved at: {os.path.join(MODEL_SAVE_DIR, f'G_estimate_{args.dataset}_{args.product}.pt')}\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluation\n########################\n\ndef calculate_threshold(model, G_estimate, data_loaders, patch_size, fpr_threshold=0.3):\n    \"\"\"\n    Calculate threshold for anomaly detection\n\n    Args:\n        model: Trained VT_AE model\n        G_estimate: Trained MDN model\n        data_loaders: List of data loaders to use for threshold calculation\n        patch_size: Patch size used in the model\n        fpr_threshold: False positive rate threshold\n\n    Returns:\n        threshold: Calculated threshold\n    \"\"\"\n    norm_loss_values = []\n    normalised_scores = []\n    mask_scores = []\n\n    for data_loader in data_loaders:\n        for images, masks in data_loader:\n            # Handle single channel images\n            if images.size(1) == 1:\n                images = torch.stack([images, images, images]).squeeze(2).permute(1, 0, 2, 3)\n\n            # Forward pass\n            vector, reconstructions = model(images.cuda())\n            pi, mu, sigma = G_estimate(vector)\n\n            # Calculate MDN loss (anomaly score)\n            mdn_loss = mdn_loss_function(vector, mu, sigma, pi, test=True)\n            norm_loss_values.append(mdn_loss.detach().cpu().numpy())\n\n            # Process masks and scores for ROC calculation\n            m = torch.nn.UpsamplingBilinear2d((512, 512))\n            norm_score = norm_loss_values[-1].reshape(-1, 1, 512//patch_size, 512//patch_size)\n            score_map = m(torch.tensor(norm_score))\n            score_map = Filter(score_map, type=0)\n\n            mask_scores.append(masks.squeeze(0).squeeze(0).cpu().numpy())\n            normalised_scores.append(score_map)\n\n    # Flatten scores and masks\n    scores = np.asarray(normalised_scores).flatten()\n    masks = np.asarray(mask_scores).flatten()\n\n    # Calculate ROC curve and find threshold\n    fpr, tpr, thresholds = roc_curve(masks, scores)\n    fp_indices = np.where(fpr <= fpr_threshold)\n    threshold = thresholds[fp_indices[-1][-1]]\n\n    return threshold\n\ndef test_model(args):\n    \"\"\"\n    Test the anomaly detection model\n\n    Args:\n        args: Command line arguments\n    \"\"\"\n    print(f\"\\n{'='*20} Testing on {args.dataset} dataset {'='*20}\")\n    print(f\"Product: {args.product}, Patch Size: {args.patch_size}\")\n\n    # Initialize wandb\n    wandb.login()\n    wandb.init(\n        project=f\"anomaly-detection-{args.dataset}-test\",\n        config={\n            \"dataset\": args.dataset,\n            \"product\": args.product,\n            \"patch_size\": args.patch_size\n        }\n    )\n\n    # Create results directory\n    results_dir = os.path.join(MODEL_SAVE_DIR, f\"results_{args.dataset}_{args.product}\")\n    os.makedirs(results_dir, exist_ok=True)\n\n    # Initialize SSIM loss\n    ssim_loss = SSIM().cuda()\n\n    # Load dataset\n    if args.dataset.lower() == 'mvtec':\n        data = Mvtec(1, root=MVTEC_DATA_DIR, product=args.product)\n    elif args.dataset.lower() == 'btad':\n        # For BTAD, we need different handling for test\n        raise NotImplementedError(\"BTAD test data loading not implemented yet\")\n    else:\n        raise ValueError(f\"Dataset {args.dataset} not supported\")\n\n    # Load models\n    model = VT_AE(patch_size=args.patch_size, train=False).cuda()\n    G_estimate = MDN().cuda()\n\n    # Load saved weights\n    model_path = os.path.join(MODEL_SAVE_DIR, f'VT_AE_{args.dataset}_{args.product}.pt')\n    g_path = os.path.join(MODEL_SAVE_DIR, f'G_estimate_{args.dataset}_{args.product}.pt')\n\n    try:\n        model.load_state_dict(torch.load(model_path))\n        G_estimate.load_state_dict(torch.load(g_path))\n        print(f\"Models loaded from {model_path} and {g_path}\")\n    except Exception as e:\n        print(f\"Error loading models: {e}\")\n        return\n\n    # Set models to eval mode\n    model.eval()\n    G_estimate.eval()\n\n    # Calculate threshold\n    print(\"Calculating threshold...\")\n    test_loaders = [data.test_norm_loader, data.test_anom_loader]\n    threshold = calculate_threshold(model, G_estimate, test_loaders, args.patch_size)\n    print(f\"Threshold: {threshold}\")\n\n    # Log threshold to wandb\n    wandb.config.update({\"threshold\": threshold})\n\n    # Evaluate on test data\n    print(\"Evaluating on test data...\")\n    with torch.no_grad():\n        # Lists to store results\n        normal_losses = []\n        anomaly_losses = []\n        normal_scores = []\n        anomaly_scores = []\n\n        # NEW: Lists to store full pixel-level data\n        full_score_maps = []\n        full_masks = []\n\n        all_y_true = []\n        all_y_pred = []\n\n        # Process normal test data\n        for images, masks in data.test_norm_loader:\n            if images.size(1) == 1:\n                images = torch.stack([images, images, images]).squeeze(2).permute(1, 0, 2, 3)\n\n            vector, reconstructions = model(images.cuda())\n            pi, mu, sigma = G_estimate(vector)\n\n            mdn_loss = mdn_loss_function(vector, mu, sigma, pi, test=True)\n            normal_losses.append(mdn_loss.sum().item())\n\n            # Generate score map\n            m = torch.nn.UpsamplingBilinear2d((512, 512))\n            norm_score = mdn_loss.detach().cpu().numpy().reshape(-1, 1, 512//args.patch_size, 512//args.patch_size)\n            score_map = m(torch.tensor(norm_score))\n            score_map = Filter(score_map.numpy(), type=0)\n\n            # Store full score map and corresponding zero mask for normal samples\n            full_score_maps.append(score_map[0][0])\n            full_masks.append(np.zeros_like(score_map[0][0]))\n\n            score_val = np.max(score_map)\n            normal_scores.append(score_val)\n\n            # Binary prediction (0: normal, 1: anomaly)\n            all_y_true.append(0)  # Ground truth: normal\n            all_y_pred.append(1 if score_val > threshold else 0)  # Prediction based on threshold\n\n        # Process anomalous test data\n        for idx, (images, masks) in enumerate(data.test_anom_loader):\n            if images.size(1) == 1:\n                images = torch.stack([images, images, images]).squeeze(2).permute(1, 0, 2, 3)\n\n            vector, reconstructions = model(images.cuda())\n            pi, mu, sigma = G_estimate(vector)\n\n            mdn_loss = mdn_loss_function(vector, mu, sigma, pi, test=True)\n            anomaly_losses.append(mdn_loss.sum().item())\n\n            # Generate score map\n            m = torch.nn.UpsamplingBilinear2d((512, 512))\n            norm_score = mdn_loss.detach().cpu().numpy().reshape(-1, 1, 512//args.patch_size, 512//args.patch_size)\n            score_map = m(torch.tensor(norm_score))\n            score_map = Filter(score_map.numpy(), type=0)\n\n            # NEW: Store full score map and corresponding mask\n            full_score_maps.append(score_map[0][0])\n            full_masks.append(masks.squeeze(0).squeeze(0).cpu().numpy())\n\n            score_val = np.max(score_map)\n            anomaly_scores.append(score_val)\n\n            # Binary prediction (0: normal, 1: anomaly)\n            all_y_true.append(1)  # Ground truth: anomaly\n            all_y_pred.append(1 if score_val > threshold else 0)  # Prediction based on threshold\n\n            # Visualize some results and save\n            if idx % 5 == 0:\n                # Enhanced visualization\n                save_path = os.path.join(results_dir, f\"anomaly_{idx}.png\")\n                plot_enhanced(images, masks, score_map[0][0], threshold, save_path)\n\n                # Region visualization\n                region_path = os.path.join(results_dir, f\"anomaly_regions_{idx}.png\")\n                visualize_regions(images, score_map[0][0], threshold, min_area=100, save_path=region_path)\n\n                # Log to wandb\n                wandb.log({\n                    f\"anomaly_sample_{idx}\": wandb.Image(save_path),\n                    f\"anomaly_regions_{idx}\": wandb.Image(region_path)\n                })\n\n        # Calculate metrics\n        print(\"\\nCalculating evaluation metrics...\")\n\n        # Convert to numpy arrays\n        y_true = np.array(all_y_true)\n        y_pred = np.array(all_y_pred)\n        roc_labels = np.concatenate((np.zeros(len(normal_losses)), np.ones(len(anomaly_losses))))\n        roc_scores = np.concatenate((normal_losses, anomaly_losses))\n\n        # Image-level ROC AUC\n        image_auc = roc_auc_score(roc_labels, roc_scores)\n\n        # Calculate pixel-level ROC AUC (PRO score)\n        # Flatten and concatenate all score maps and masks\n        pixel_scores = np.concatenate([s.flatten() for s in full_score_maps])\n        pixel_masks = np.concatenate([m.flatten() for m in full_masks])\n\n        # Now the dimensions will match\n        pro_score = roc_auc_score(pixel_masks, pixel_scores)\n\n        # Precision-Recall AUC\n        precision, recall, _ = precision_recall_curve(roc_labels, roc_scores)\n        pr_auc = auc(recall, precision)\n\n        # Additional metrics\n        f1 = f1_score(y_true, y_pred)\n        accuracy = accuracy_score(y_true, y_pred)\n        precision_score_val = precision_score(y_true, y_pred)\n        recall_score_val = recall_score(y_true, y_pred)\n\n        # Generate ROC curve\n        fpr, tpr, _ = roc_curve(roc_labels, roc_scores)\n\n        # Plot and save ROC curve\n        roc_path = os.path.join(results_dir, \"roc_curve.png\")\n        plot_roc_curve(fpr, tpr, image_auc, roc_path)\n\n        # Plot and save PR curve\n        pr_path = os.path.join(results_dir, \"pr_curve.png\")\n        plot_precision_recall_curve(precision, recall, pr_auc, pr_path)\n\n        # Plot and save confusion matrix\n        cm_path = os.path.join(results_dir, \"confusion_matrix.png\")\n        plot_confusion_matrix(y_true, y_pred, cm_path)\n\n        # Plot and save score distributions\n        dist_path = os.path.join(results_dir, \"score_distributions.png\")\n        plot_score_distributions(normal_scores, anomaly_scores, threshold, dist_path)\n\n        # Log results to wandb\n        wandb.log({\n            \"image_level_auc\": image_auc,\n            \"pixel_level_auc\": pro_score,\n            \"pr_auc\": pr_auc,\n            \"f1_score\": f1,\n            \"accuracy\": accuracy,\n            \"precision\": precision_score_val,\n            \"recall\": recall_score_val,\n            \"roc_curve\": wandb.Image(roc_path),\n            \"pr_curve\": wandb.Image(pr_path),\n            \"confusion_matrix\": wandb.Image(cm_path),\n            \"score_distributions\": wandb.Image(dist_path)\n        })\n\n        # Log classification report\n        cls_report = classification_report(y_true, y_pred, target_names=['Normal', 'Anomaly'])\n        with open(os.path.join(results_dir, \"classification_report.txt\"), \"w\") as f:\n            f.write(cls_report)\n\n        print(f\"\\nResults for {args.dataset} - {args.product}:\")\n        print(f\"Image-level AUC: {image_auc:.4f}\")\n        print(f\"Pixel-level AUC (PRO): {pro_score:.4f}\")\n        print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision_score_val:.4f}\")\n        print(f\"Recall: {recall_score_val:.4f}\")\n        print(\"\\nClassification Report:\")\n        print(cls_report)\n\n    # Finish wandb\n    wandb.finish()","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"def main():\n    # Check if running in Jupyter/Colab environment\n    in_colab = 'google.colab' in str(get_ipython())\n\n    if in_colab:\n        # Use default values or allow user to set them directly in Colab\n        class Args:\n            def __init__(self):\n                self.dataset = 'mvtec'  # Default dataset\n                self.data_path = MVTEC_DATA_DIR  # Default path\n                self.product = 'bottle'  # Default product\n                self.patch_size = 64  # Default patch size\n                self.mode = 'train'  # Default mode\n                self.batch_size = 8  # Default batch size\n                self.learning_rate = 0.0001  # Default learning rate\n                self.epochs = 100  # Default epochs\n\n        args = Args()\n        print(\"\\nRunning in Colab environment. Using default values:\")\n        print(f\"Dataset: {args.dataset}\")\n        print(f\"Product: {args.product}\")\n        print(f\"Mode: {args.mode}\")\n        print(f\"Patch size: {args.patch_size}\")\n        print(f\"Batch size: {args.batch_size}\")\n        print(f\"Learning rate: {args.learning_rate}\")\n        print(f\"Epochs: {args.epochs}\")\n        print(\"\\nTo change these values, set them directly before running:\")\n        print(\"Example: args.dataset = 'btad'; args.product = '01'\")\n\n    else:\n        # Parse command line arguments as before\n        parser = argparse.ArgumentParser(description='Anomaly Detection with Vision Transformer')\n\n        # Dataset parameters\n        parser.add_argument('--dataset', type=str, default='mvtec', choices=['mvtec', 'btad'],\n                            help='Dataset to use (mvtec or btad)')\n        parser.add_argument('--data_path', type=str, default=MVTEC_DATA_DIR,\n                            help='Path to dataset (defaults to Google Drive path)')\n        parser.add_argument('--product', type=str, default='bottle',\n                            help='Product category for MVTec dataset')\n\n        # Model parameters\n        parser.add_argument('--patch_size', type=int, default=64,\n                            help='Patch size for Vision Transformer')\n\n        # Training parameters\n        parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'],\n                            help='Mode: train or test')\n        parser.add_argument('--batch_size', type=int, default=8,\n                            help='Batch size for training')\n        parser.add_argument('--learning_rate', type=float, default=0.0001,\n                            help='Learning rate')\n        parser.add_argument('--epochs', type=int, default=100,\n                            help='Number of epochs to train')\n\n        args = parser.parse_args()\n\n        # Print configuration\n        print(\"\\nConfiguration:\")\n        print(f\"Mode: {args.mode}\")\n        print(f\"Dataset: {args.dataset}\")\n        print(f\"Data path: {args.data_path}\")\n        print(f\"Product: {args.product}\")\n        print(f\"Patch size: {args.patch_size}\")\n        if args.mode == 'train':\n            print(f\"Batch size: {args.batch_size}\")\n            print(f\"Learning rate: {args.learning_rate}\")\n            print(f\"Epochs: {args.epochs}\")\n\n    # Set random seeds for reproducibility\n    random.seed(123)\n    np.random.seed(123)\n    torch.manual_seed(123)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(123)\n\n    # Check CUDA availability\n    if torch.cuda.is_available():\n        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n    else:\n        print(\"CUDA is not available. Using CPU.\")\n\n    # Run appropriate function based on mode\n    if args.mode == 'train':\n        train_model(args)\n    elif args.mode == 'test':\n        test_model(args)\n\n# Function to run directly in Colab\ndef run_in_colab(dataset='mvtec', product='bottle', mode='train', patch_size=64,\n                batch_size=8, learning_rate=0.0001, epochs=100):\n    \"\"\"\n    Run the anomaly detection model directly from Colab\n\n    Args:\n        dataset: Dataset name ('mvtec' or 'btad')\n        product: Product category\n                MVTec: 'bottle', 'cable', etc.\n                BTAD: '01', '02', '03'\n        mode: 'train' or 'test'\n        patch_size: Patch size for Vision Transformer\n        batch_size: Batch size for training\n        learning_rate: Learning rate\n        epochs: Number of epochs\n    \"\"\"\n    class Args:\n        def __init__(self):\n            self.dataset = dataset\n\n            if dataset.lower() == 'mvtec':\n                self.data_path = MVTEC_DATA_DIR\n            else:\n                self.data_path = BTAD_DATA_DIR\n\n            self.product = product\n            self.patch_size = patch_size\n            self.mode = mode\n            self.batch_size = batch_size\n            self.learning_rate = learning_rate\n            self.epochs = epochs\n\n    args = Args()\n\n    # Print configuration\n    print(\"\\nConfiguration:\")\n    print(f\"Dataset: {args.dataset}\")\n    print(f\"Product: {args.product}\")\n    print(f\"Mode: {args.mode}\")\n    print(f\"Patch size: {args.patch_size}\")\n    print(f\"Batch size: {args.batch_size}\")\n    print(f\"Learning rate: {args.learning_rate}\")\n    print(f\"Epochs: {args.epochs}\")\n\n    # Set random seeds for reproducibility\n    random.seed(123)\n    np.random.seed(123)\n    torch.manual_seed(123)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(123)\n\n    # Check CUDA availability\n    if torch.cuda.is_available():\n        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n    else:\n        print(\"CUDA is not available. Using CPU.\")\n\n    # Run appropriate function based on mode\n    if args.mode == 'train':\n        train_model(args)\n    elif args.mode == 'test':\n        test_model(args)\n    else:\n        print(f\"Invalid mode: {args.mode}. Choose 'train' or 'test'.\")\n\n#run_in_colab(dataset='mvtec', product='bottle', mode='train')\nrun_in_colab(dataset='mvtec', product='bottle', mode='test')\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}